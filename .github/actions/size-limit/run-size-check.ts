#!/usr/bin/env bun

import { readFileSync, mkdirSync, rmSync, existsSync, readdirSync } from "node:fs";
import { join } from "node:path";
import { regex } from "arkregex";
import { spawn } from "bun";

interface SizeLimitResult {
	package: string;
	file: string;
	size: string;
	limit: string;
	status: "‚úÖ" | "‚ùå";
	diff?: string;
}

type SizeInBytes = number;

// Convert size string (e.g., "711 B", "1.2 kB", "5 MB", "2.5 GiB") to bytes
const parseSizeToBytes = (sizeStr: string): SizeInBytes => {
	// Match number and optional unit (case-insensitive)
	const match = sizeStr.match(/^([0-9.]+)\s*([a-z]*)$/i);
	if (!match || !match[1]) {
		return 0;
	}

	const value = Number.parseFloat(match[1]);
	const unit = match[2]?.toLowerCase() ?? "";

	// Handle bytes (no unit or just 'b')
	if (!unit || unit === "b") {
		return value;
	}

	// Map units to multipliers (using 1024-based)
	const multipliers: Record<string, number> = {
		k: 1024 ** 1,
		kb: 1024 ** 1,
		kib: 1024 ** 1,
		m: 1024 ** 2,
		mb: 1024 ** 2,
		mib: 1024 ** 2,
		g: 1024 ** 3,
		gb: 1024 ** 3,
		gib: 1024 ** 3,
	};

	const multiplier = multipliers[unit];
	if (multiplier === undefined) {
		return 0;
	}

	return value * multiplier;
};

// Calculate percentage difference
const calculateDiff = (current: SizeInBytes, baseline: SizeInBytes): string => {
	if (baseline === 0) {
		return current > 0 ? "+‚àû%" : "‚Äî";
	}
	const diff = ((current - baseline) / baseline) * 100;
	// Show "0.0%" when diff is exactly 0, otherwise show "‚Äî" for very small changes (< 0.1%)
	if (Math.abs(diff) < 0.1) {
		return diff === 0 ? "0.0%" : "‚Äî";
	}
	const sign = diff > 0 ? "+" : "";
	return `${sign}${diff.toFixed(1)}%`;
};

// Helper function to get filename from size-limit config in package.json
const getFilenameFromConfig = (packageName: string): string | null => {
	try {
		// Try to find package.json for this package
		// Package name could be "arkenv" or "./packages/arkenv" or "packages/arkenv"
		let packagePath = packageName;
		if (packagePath.startsWith("./")) {
			packagePath = packagePath.slice(2);
		}
		if (!packagePath.startsWith("packages/")) {
			packagePath = `packages/${packagePath}`;
		}

		const packageJsonPath = join(process.cwd(), packagePath, "package.json");
		const packageJson = JSON.parse(readFileSync(packageJsonPath, "utf-8"));
		const sizeLimitConfig = packageJson["size-limit"];

		if (Array.isArray(sizeLimitConfig) && sizeLimitConfig.length > 0) {
			const firstConfig = sizeLimitConfig[0];
			if (firstConfig.path) {
				// Extract filename from path (e.g., "dist/index.js" -> "index.js")
				const pathParts = firstConfig.path.split("/");
				return pathParts[pathParts.length - 1] || null;
			}
		}
	} catch {
		// If we can't read the config, return null
	}
	return null;
};

// Get inputs from environment
const turboToken = process.env.INPUT_TURBO_TOKEN;
const turboTeam = process.env.INPUT_TURBO_TEAM;
const filter = process.env.INPUT_FILTER || "./packages/*";
const baseBranch = process.env.INPUT_BASE_BRANCH || "main";
const headBranch = process.env.INPUT_HEAD_BRANCH || "";
const isPR = process.env.GITHUB_EVENT_NAME === "pull_request";
const isReleasePR = headBranch === "changeset-release/main";

// Set Turbo environment variables if provided
if (turboToken) {
	process.env.TURBO_TOKEN = turboToken;
}
if (turboTeam) {
	process.env.TURBO_TEAM = turboTeam;
}

// Function to parse size-limit output
const parseSizeLimitOutput = (
	sizeOutput: string,
	filter: string,
): SizeLimitResult[] => {
	const results: SizeLimitResult[] = [];
	const lines = sizeOutput.split("\n");

	let currentPackage = "";
	let currentFile = "";
	let currentSize = "";
	let currentLimit = "";
	let currentStatus: "‚úÖ" | "‚ùå" = "‚úÖ";
	let parsingMode: "colon" | "hash" | null = null;

	const normalizePackageName = (pkgName: string) => {
		const cleaned = pkgName.replace(/^[./]+/, "");
		if (cleaned.startsWith("@")) {
			return cleaned;
		}
		if (cleaned.includes("/")) {
			const segments = cleaned.split("/");
			const scopeIndex = segments.findIndex((part) => part.startsWith("@"));
			return scopeIndex >= 0
				? segments.slice(scopeIndex).join("/")
				: (segments.at(-1) ?? cleaned);
		}
		return cleaned;
	};

	const stripAnsiRegex = regex("\x1B\\[[0-?]*[ -/]*[@-~]", "g");
	const controlCharsRegex = regex("[\u0000-\u0008\u000B-\u001F\u007F]", "g");

	const stripAnsi = (text: string) => text.replace(stripAnsiRegex, "");
	const sanitizeLine = (text: string) =>
		stripAnsi(text).replace(controlCharsRegex, "");

	const flushCurrentPackage = () => {
		if (currentPackage && currentSize && currentLimit) {
			// Extract filename: if currentFile has a path, use the last part
			// Handle both "dist/index.js" and "index.js" formats
			// If no filename found in output, try to get it from package.json config
			let filename = currentFile
				? (currentFile.includes("/")
						? currentFile.split("/").pop()
						: currentFile) || null
				: null;

			// Fallback to reading from package.json size-limit config
			if (!filename) {
				filename = getFilenameFromConfig(currentPackage);
			}

			// Final fallback to "bundle" if we still can't determine the file
			filename = filename || "bundle";

			results.push({
				package: currentPackage,
				file: filename,
				size: currentSize,
				limit: currentLimit,
				status: currentStatus,
			});
		}
	};

	const startPackage = (pkgName: string) => {
		if (currentPackage === pkgName) {
			return;
		}

		flushCurrentPackage();
		currentPackage = pkgName;
		currentFile = "";
		currentSize = "";
		currentLimit = "";
		currentStatus = "‚úÖ";
	};

	const parseMessageLine = (message: string) => {
		if (!message) {
			return;
		}

		const fileMatch = message.match(
			/([^\s]+\.(?:js|ts|jsx|tsx|cjs|mjs|d\.ts))/i,
		);
		if (fileMatch?.[1]) {
			currentFile = fileMatch[1];
		}

		// Match "Size limit: X kB" or "Limit: X kB"
		const limitMatch = message.match(
			/(?:Size\s+limit|Limit):\s+([0-9.]+\s*(?:[kKmMgG](?:i)?[bB]|[bB]))/i,
		);
		if (limitMatch?.[1]) {
			currentLimit = limitMatch[1];
		}

		// Match "Size: X kB" or just "X kB" when in context
		const sizeMatch = message.match(
			/(?:Size|Size is):\s+([0-9.]+\s*(?:[kKmMgG](?:i)?[bB]|[bB]))/i,
		);
		if (sizeMatch?.[1]) {
			currentSize = sizeMatch[1];
		}

		// Match table format: "package  size  limit" (space-separated)
		const tableMatch = message.match(
			/^([@a-z0-9][@a-z0-9/_-]*)\s+([0-9.]+\s*(?:[kKmMgG](?:i)?[bB]|[bB]))\s+([0-9.]+\s*(?:[kKmMgG](?:i)?[bB]|[bB]))/i,
		);
		if (tableMatch?.[1] && tableMatch?.[2] && tableMatch?.[3]) {
			const pkgName = normalizePackageName(tableMatch[1]);
			startPackage(pkgName);
			currentSize = tableMatch[2];
			currentLimit = tableMatch[3];
		}

		// Match direct size-limit output format: "dist/index.js: 1.2 kB (limit: 2 kB)"
		const directMatch = message.match(
			/([^\s]+\.(?:js|ts|jsx|tsx|cjs|mjs|d\.ts)):\s+([0-9.]+\s*(?:[kKmMgG](?:i)?[bB]|[bB]))\s*\(limit:\s*([0-9.]+\s*(?:[kKmMgG](?:i)?[bB]|[bB]))\)/i,
		);
		if (directMatch?.[1] && directMatch?.[2] && directMatch?.[3]) {
			currentFile = directMatch[1];
			currentSize = directMatch[2];
			currentLimit = directMatch[3];
		}

		// Match format: "X kB of Y kB" or "X kB / Y kB"
		const sizeLimitMatch = message.match(
			/([0-9.]+\s*(?:[kKmMgG](?:i)?[bB]|[bB]))\s+(?:of|\/)\s+([0-9.]+\s*(?:[kKmMgG](?:i)?[bB]|[bB]))/i,
		);
		if (sizeLimitMatch?.[1] && sizeLimitMatch?.[2]) {
			currentSize = sizeLimitMatch[1];
			currentLimit = sizeLimitMatch[2];
		}

		if (
			message.includes("‚úñ") ||
			message.includes("ERROR") ||
			message.includes("FAIL") ||
			message.toLowerCase().includes("exceeded") ||
			message.includes("‚ùå")
		) {
			currentStatus = "‚ùå";
		}
	};

	for (const line of lines) {
		const strippedLine = sanitizeLine(line);

		// Skip empty lines
		if (!strippedLine.trim()) {
			continue;
		}

		// Match Turbo colon format: "package:size:message"
		const colonMatch = strippedLine.match(
			/^([@a-z0-9][@a-z0-9/_-]*):size:(.*)$/i,
		);
		if (colonMatch?.[1]) {
			parsingMode = "colon";
			const pkgName = normalizePackageName(colonMatch[1]);
			startPackage(pkgName);

			const message = colonMatch[2]?.trim() ?? "";
			parseMessageLine(message);
			continue;
		}

		// Match Turbo hash format: "package#size"
		const hashMatch = strippedLine.match(/^\s*([@a-z0-9][@a-z0-9/_-]*)#size/i);
		if (hashMatch?.[1]) {
			parsingMode = "hash";
			const pkgName = normalizePackageName(hashMatch[1]);
			startPackage(pkgName);
			continue;
		}

		// If we detect a new package in script output, reset parsing mode
		const scriptMatch = strippedLine.match(/>\s*([@a-z0-9][@a-z0-9/_-]*)@\S+/i);
		if (scriptMatch?.[1]) {
			const pkgName = normalizePackageName(scriptMatch[1]);
			// Only start a new package if we're not already in one, or if it's different
			if (!currentPackage || currentPackage !== pkgName) {
				parsingMode = null; // Reset parsing mode for direct output
				startPackage(pkgName);
			}
			continue;
		}

		// Handle indented lines after hash format
		if (parsingMode === "hash" && /^\s+/.test(strippedLine)) {
			parseMessageLine(strippedLine.trim());
			continue;
		}

		// Try to parse direct size-limit output (not wrapped by Turbo)
		// Look for lines that contain size information even without Turbo prefix
		if (strippedLine.match(/[0-9.]+\s*(?:[kKmMgG](?:i)?[bB]|[bB])/i)) {
			// Try to extract package name from context (e.g., "> arkenv@0.7.3 size")
			const pkgContextMatch = strippedLine.match(
				/>\s*([@a-z0-9][@a-z0-9/_-]*)@/i,
			);
			if (pkgContextMatch?.[1]) {
				const pkgName = normalizePackageName(pkgContextMatch[1]);
				startPackage(pkgName);
			} else if (!currentPackage) {
				// If we don't have a current package, try to infer from filter
				// Extract package name from filter pattern like "./packages/arkenv" or "arkenv"
				const filterMatch = filter.match(
					/(?:packages\/)?([@a-z0-9][@a-z0-9/_-]*)/i,
				);
				if (filterMatch?.[1]) {
					const pkgName = normalizePackageName(filterMatch[1]);
					startPackage(pkgName);
				}
			}

			// Parse the line for size information
			parseMessageLine(strippedLine);
		}
	}

	// Add last package if we have data
	flushCurrentPackage();

	return results;
};

// Function to run size-limit and parse results
const runSizeLimit = async (): Promise<{
	results: SizeLimitResult[];
	hasErrors: boolean;
	rawOutput?: string;
}> => {
	let sizeOutput = "";
	let hasErrors = false;

	try {
		const proc = spawn(["pnpm", "run", "size", "--filter", filter], {
			stdout: "pipe",
			stderr: "pipe",
		});

		const [stdout, stderr] = await Promise.all([
			new Response(proc.stdout).text(),
			new Response(proc.stderr).text(),
		]);

		const exitCode = await proc.exited;
		sizeOutput = stdout + stderr;
		hasErrors = exitCode !== 0;
	} catch (error) {
		sizeOutput = error instanceof Error ? error.message : String(error);
		hasErrors = true;
	}

	const results = parseSizeLimitOutput(sizeOutput, filter);
	return { results, hasErrors, rawOutput: sizeOutput };
};

// Function to get package names from filter
const getPackageNames = (filter: string): string[] => {
	const packages: string[] = [];
	
	// If filter is a wildcard, discover packages from packages directory
	if (filter.includes("*")) {
		try {
			const packagesDir = join(process.cwd(), "packages");
			if (existsSync(packagesDir)) {
				const entries = readdirSync(packagesDir, { withFileTypes: true });
				for (const entry of entries) {
					if (entry.isDirectory()) {
						const packageJsonPath = join(
							packagesDir,
							entry.name,
							"package.json",
						);
						if (existsSync(packageJsonPath)) {
							const packageJson = JSON.parse(
								readFileSync(packageJsonPath, "utf-8"),
							);
							if (packageJson.name) {
								packages.push(packageJson.name);
							}
						}
					}
				}
			}
		} catch (error) {
			console.log(
				`‚ö†Ô∏è Failed to discover packages: ${error instanceof Error ? error.message : String(error)}`,
			);
		}
	} else {
		// Extract package name from filter like "./packages/arkenv"
		const match = filter.match(/packages\/([@a-z0-9][@a-z0-9/_-]*)/i);
		if (match?.[1]) {
			// Try to read package.json to get the actual package name
			const packageJsonPath = join(
				process.cwd(),
				"packages",
				match[1],
				"package.json",
			);
			if (existsSync(packageJsonPath)) {
				try {
					const packageJson = JSON.parse(
						readFileSync(packageJsonPath, "utf-8"),
					);
					if (packageJson.name) {
						packages.push(packageJson.name);
					} else {
						packages.push(match[1]);
					}
				} catch {
					packages.push(match[1]);
				}
			} else {
				packages.push(match[1]);
			}
		}
	}
	
	return packages.length > 0 ? packages : [];
};

// Function to get latest version of a package from npm
const getLatestVersion = async (packageName: string): Promise<string | null> => {
	try {
		const proc = spawn(["npm", "view", packageName, "version"], {
			stdout: "pipe",
			stderr: "pipe",
		});
		
		const [stdout, stderr] = await Promise.all([
			new Response(proc.stdout).text(),
			new Response(proc.stderr).text(),
		]);
		
		const exitCode = await proc.exited;
		if (exitCode !== 0) {
			console.log(`‚ö†Ô∏è Failed to get version for ${packageName}: ${stderr}`);
			return null;
		}
		
		return stdout.trim();
	} catch (error) {
		console.log(
			`‚ö†Ô∏è Error getting version for ${packageName}: ${error instanceof Error ? error.message : String(error)}`,
		);
		return null;
	}
};

// Function to download and extract npm package
const downloadNpmPackage = async (
	packageName: string,
	version: string,
	targetDir: string,
): Promise<boolean> => {
	try {
		// Create target directory
		if (!existsSync(targetDir)) {
			mkdirSync(targetDir, { recursive: true });
		}
		
		// Construct tarball URL
		// For scoped packages: @scope/name -> scope-name-version.tgz
		// For unscoped packages: name -> name-version.tgz
		const tarballName = packageName.startsWith("@")
			? `${packageName.slice(1).replace("/", "-")}-${version}.tgz`
			: `${packageName}-${version}.tgz`;
		const tarballUrl = `https://registry.npmjs.org/${packageName}/-/${tarballName}`;
		
		console.log(`üì¶ Downloading ${packageName}@${version}...`);
		const downloadProc = spawn([
			"curl",
			"-L",
			"-o",
			join(targetDir, "package.tgz"),
			tarballUrl,
		], {
			stdout: "pipe",
			stderr: "pipe",
		});
		
		const downloadExitCode = await downloadProc.exited;
		if (downloadExitCode !== 0) {
			console.log(`‚ö†Ô∏è Failed to download ${packageName}@${version}`);
			return false;
		}
		
		// Extract tarball
		const extractProc = spawn([
			"tar",
			"-xzf",
			join(targetDir, "package.tgz"),
			"-C",
			targetDir,
			"--strip-components=1",
		], {
			stdout: "pipe",
			stderr: "pipe",
		});
		
		const extractExitCode = await extractProc.exited;
		if (extractExitCode !== 0) {
			console.log(`‚ö†Ô∏è Failed to extract ${packageName}@${version}`);
			return false;
		}
		
		return true;
	} catch (error) {
		console.log(
			`‚ö†Ô∏è Error downloading ${packageName}@${version}: ${error instanceof Error ? error.message : String(error)}`,
		);
		return false;
	}
};

// Function to get baseline sizes from npm
const getBaselineSizesFromNpm = async (
	filter: string,
): Promise<Map<string, SizeInBytes>> => {
	const baselineMap = new Map<string, SizeInBytes>();
	
	if (!isPR || !isReleasePR) {
		return baselineMap;
	}
	
	console.log("üì¶ Fetching baseline sizes from npm (latest published versions)...");
	
	const packageNames = getPackageNames(filter);
	const tempDir = join(process.cwd(), ".npm-baseline");
	
	// Clean up temp directory if it exists
	if (existsSync(tempDir)) {
		rmSync(tempDir, { recursive: true, force: true });
	}
	mkdirSync(tempDir, { recursive: true });
	
	try {
		for (const packageName of packageNames) {
			// Get latest version
			const version = await getLatestVersion(packageName);
			if (!version) {
				console.log(
					`‚ö†Ô∏è Could not get version for ${packageName}, skipping npm baseline`,
				);
				continue;
			}
			
			console.log(`üì¶ Found ${packageName}@${version} on npm`);
			
			// Download package
			const packageDir = join(tempDir, packageName);
			const downloaded = await downloadNpmPackage(
				packageName,
				version,
				packageDir,
			);
			
			if (!downloaded) {
				console.log(`‚ö†Ô∏è Failed to download ${packageName}, skipping`);
				continue;
			}
			
			// Read package.json to find size-limit config
			const packageJsonPath = join(packageDir, "package.json");
			if (!existsSync(packageJsonPath)) {
				console.log(`‚ö†Ô∏è package.json not found for ${packageName}, skipping`);
				continue;
			}
			
			const packageJson = JSON.parse(
				readFileSync(packageJsonPath, "utf-8"),
			);
			const sizeLimitConfig = packageJson["size-limit"];
			
			if (!Array.isArray(sizeLimitConfig) || sizeLimitConfig.length === 0) {
				console.log(
					`‚ö†Ô∏è No size-limit config found for ${packageName}, skipping`,
				);
				continue;
			}
			
			// Get dist file path from config
			const firstConfig = sizeLimitConfig[0];
			const distPath = firstConfig.path;
			if (!distPath) {
				console.log(`‚ö†Ô∏è No dist path in size-limit config for ${packageName}`);
				continue;
			}
			
			// Calculate file size
			const fullDistPath = join(packageDir, distPath);
			if (!existsSync(fullDistPath)) {
				console.log(
					`‚ö†Ô∏è Dist file ${distPath} not found in npm package ${packageName}@${version}`,
				);
				continue;
			}
			
			const stats = await import("node:fs/promises").then((fs) =>
				fs.stat(fullDistPath),
			);
			const sizeBytes = stats.size;
			
			// Extract filename from path
			const filename = distPath.split("/").pop() || "bundle";
			const key = `${packageName}:${filename}`;
			baselineMap.set(key, sizeBytes);
			
			console.log(`‚úÖ Baseline for ${key}: ${sizeBytes} bytes`);
		}
		
		if (baselineMap.size === 0) {
			console.log(
				"‚ö†Ô∏è No baseline sizes found from npm. This might be the first release.",
			);
		} else {
			console.log(`‚úÖ Found ${baselineMap.size} baseline size(s) from npm`);
		}
	} catch (error) {
		console.log(
			`‚ö†Ô∏è Failed to get baseline sizes from npm: ${error instanceof Error ? error.message : String(error)}`,
		);
	} finally {
		// Clean up temp directory
		if (existsSync(tempDir)) {
			rmSync(tempDir, { recursive: true, force: true });
		}
	}
	
	return baselineMap;
};

// Function to get baseline sizes from base branch
const getBaselineSizes = async (
	baseBranch: string,
): Promise<Map<string, SizeInBytes>> => {
	const baselineMap = new Map<string, SizeInBytes>();

	if (!isPR) {
		return baselineMap;
	}

	try {
		// Get current branch/commit
		const currentBranchProc = spawn(["git", "rev-parse", "HEAD"], {
			stdout: "pipe",
		});
		const currentCommit = (
			await new Response(currentBranchProc.stdout).text()
		).trim();

		// Check if base branch exists
		const checkBranchProc = spawn(
			["git", "ls-remote", "--heads", "origin", baseBranch],
			{ stdout: "pipe", stderr: "pipe" },
		);
		const checkBranchOutput = await new Response(checkBranchProc.stdout).text();

		if (!checkBranchOutput.trim()) {
			console.log(
				`‚ö†Ô∏è Base branch ${baseBranch} not found, skipping baseline comparison`,
			);
			return baselineMap;
		}

		console.log(`üìä Fetching baseline sizes from ${baseBranch}...`);

		// Fetch the base branch
		const fetchProc = spawn(["git", "fetch", "origin", baseBranch], {
			stdout: "pipe",
			stderr: "pipe",
		});
		const fetchExitCode = await fetchProc.exited;
		if (fetchExitCode !== 0) {
			console.log(
				`‚ö†Ô∏è Failed to fetch ${baseBranch}, skipping baseline comparison`,
			);
			return baselineMap;
		}

		// Checkout base branch temporarily
		const checkoutProc = spawn(["git", "checkout", `origin/${baseBranch}`], {
			stdout: "pipe",
			stderr: "pipe",
		});
		const checkoutExitCode = await checkoutProc.exited;
		if (checkoutExitCode !== 0) {
			console.log(
				`‚ö†Ô∏è Failed to checkout ${baseBranch}, skipping baseline comparison`,
			);
			return baselineMap;
		}

		// Install dependencies and build
		try {
			const installProc = spawn(["pnpm", "install"], {
				stdout: "pipe",
				stderr: "pipe",
			});
			const installExitCode = await installProc.exited;
			if (installExitCode !== 0) {
				console.log(
					`‚ö†Ô∏è Failed to install dependencies on ${baseBranch}, skipping baseline comparison`,
				);
				return baselineMap;
			}

			const buildProc = spawn(["pnpm", "run", "build", "--filter", filter], {
				stdout: "pipe",
				stderr: "pipe",
			});
			const buildExitCode = await buildProc.exited;
			if (buildExitCode !== 0) {
				console.log(
					`‚ö†Ô∏è Failed to build on ${baseBranch}, skipping baseline comparison`,
				);
				return baselineMap;
			}

			// Run size-limit on base branch
			const baselineResult = await runSizeLimit();

			// Check if baseline run had errors before populating baseline map
			if (baselineResult.hasErrors) {
				console.log(
					"‚ö†Ô∏è Baseline size-limit run failed, skipping baseline comparison. Diff values will not be available.",
				);
				return baselineMap;
			}

			// Create a map of package+file -> size in bytes
			for (const result of baselineResult.results) {
				const key = `${result.package}:${result.file}`;
				const sizeBytes = parseSizeToBytes(result.size);
				baselineMap.set(key, sizeBytes);
			}

			// Always log baseline status for debugging
			if (baselineMap.size === 0) {
				console.log(
					"‚ö†Ô∏è No baseline sizes found. This might be the first run or baseline parsing failed.",
				);
				console.log(
					`üìä Baseline results array length: ${baselineResult.results.length}`,
				);
				if (baselineResult.results.length > 0) {
					console.log(
						`üìä First baseline result: ${JSON.stringify(baselineResult.results[0])}`,
					);
				} else {
					// If no results parsed, log a sample of the raw output to help debug parsing issues
					console.log(
						"‚ö†Ô∏è Baseline run completed but no results were parsed. This suggests a parsing issue.",
					);
					if (baselineResult.rawOutput) {
						const outputLines = baselineResult.rawOutput
							.split("\n")
							.filter((l) => l.trim());
						const sampleLines = outputLines.slice(0, 20).join("\n");
						console.log(
							`üìä Sample of baseline output (first 20 non-empty lines):\n${sampleLines}`,
						);
						if (outputLines.length > 20) {
							console.log(`... (${outputLines.length - 20} more lines)`);
						}
						if (outputLines.length === 0) {
							console.log("‚ö†Ô∏è Baseline output is completely empty!");
						}
					} else {
						console.log("‚ö†Ô∏è Baseline rawOutput is undefined!");
					}
				}
			} else {
				console.log(`‚úÖ Found ${baselineMap.size} baseline size(s)`);
				for (const [key, size] of baselineMap.entries()) {
					console.log(`  - ${key}: ${size} bytes`);
				}
			}
		} finally {
			// Checkout back to current commit
			const restoreProc = spawn(["git", "checkout", currentCommit], {
				stdout: "pipe",
				stderr: "pipe",
			});
			const [restoreStdout, restoreStderr] = await Promise.all([
				new Response(restoreProc.stdout).text(),
				new Response(restoreProc.stderr).text(),
			]);
			const restoreExitCode = await restoreProc.exited;
			if (restoreExitCode !== 0) {
				console.error(
					`‚ùå Failed to restore git commit ${currentCommit}. Repository may be in an incorrect state.`,
				);
				console.error("Git stdout:", restoreStdout);
				console.error("Git stderr:", restoreStderr);
				process.exit(1);
			}
		}
	} catch (error) {
		console.log(
			`‚ö†Ô∏è Failed to get baseline sizes: ${error instanceof Error ? error.message : String(error)}`,
		);
	}

	return baselineMap;
};

// Main execution
console.log("üîç Running size-limit checks for all packages...");

// Get baseline sizes if in PR context
// For release PRs (changeset-release/main), compare against npm instead of base branch
const baselineSizes = isPR
	? isReleasePR
		? await getBaselineSizesFromNpm(filter)
		: await getBaselineSizes(baseBranch)
	: new Map();

// Reinstall dependencies for current branch after baseline check
// (getBaselineSizes checks out base branch and overwrites node_modules)
// This is only needed when comparing against base branch, not npm
if (isPR && !isReleasePR) {
	console.log("üì¶ Reinstalling dependencies for current branch...");
	const reinstallProc = spawn(["pnpm", "install"], {
		stdout: "pipe",
		stderr: "pipe",
	});
	const reinstallExitCode = await reinstallProc.exited;
	if (reinstallExitCode !== 0) {
		console.log(
			"‚ö†Ô∏è Failed to reinstall dependencies, size check may be inaccurate",
		);
	}

	// Rebuild project to clear base branch artifacts before size check
	console.log("üî® Rebuilding project for current branch...");
	const rebuildProc = spawn(["pnpm", "run", "build", "--filter", filter], {
		stdout: "pipe",
		stderr: "pipe",
	});
	const rebuildExitCode = await rebuildProc.exited;
	if (rebuildExitCode !== 0) {
		console.error("‚ùå Failed to rebuild project, size check may be inaccurate");
		process.exit(1);
	}
}

// Run size-limit on current branch
const { results, hasErrors } = await runSizeLimit();

// Calculate diffs and add to results
for (const result of results) {
	const key = `${result.package}:${result.file}`;
	let baselineSize = baselineSizes.get(key);

	// If not found, try alternative key formats (for backwards compatibility)
	// e.g., if current has "index.js" but baseline has "bundle", or vice versa
	if (baselineSize === undefined && baselineSizes.size > 0) {
		// Try with "bundle" as fallback filename (for old baselines that used "bundle")
		const bundleKey = `${result.package}:bundle`;
		baselineSize = baselineSizes.get(bundleKey);

		// If still not found, try to find any file for this package
		// This handles cases where filename format changed between baseline and current
		if (baselineSize === undefined) {
			for (const [baselineKey, size] of baselineSizes.entries()) {
				if (baselineKey.startsWith(`${result.package}:`)) {
					baselineSize = size;
					break;
				}
			}
		}
	}

	if (baselineSize !== undefined) {
		const currentSize = parseSizeToBytes(result.size);
		result.diff = calculateDiff(currentSize, baselineSize);
	} else {
		// Only log if there's an issue (can't compute diff)
		if (baselineSizes.size > 0) {
			const availableKeys = Array.from(baselineSizes.keys()).join(", ");
			console.log(
				`‚ö†Ô∏è No baseline found for ${key}. Available keys: ${availableKeys}`,
			);
		} else {
			console.log(
				`‚ö†Ô∏è No baseline found for ${key}. Baseline map is empty (size: ${baselineSizes.size}).`,
			);
		}
		result.diff = "‚Äî";
	}
}

// Create the table
let result: string;
if (results.length === 0) {
	result = "```\nNo results found\n```";
	console.log("‚ö†Ô∏è Could not parse size-limit output");
} else {
	const tableRows = results
		.map(
			(r) =>
				`| \`${r.package}\` | \`${r.file}\` | ${r.size} | ${r.limit} | ${r.diff ?? "‚Äî"} | ${r.status} |`,
		)
		.join("\n");
	result = `| Package | File | Size | Limit | Diff | Status |\n|---------|------|------|-------|------|--------|\n${tableRows}`;
}

// Set GitHub outputs
const githubOutput = process.env.GITHUB_OUTPUT;
if (githubOutput) {
	const fs = await import("node:fs/promises");
	const output = `result<<EOF\n${result}\nEOF\nhas_errors=${hasErrors}\n`;
	await fs.appendFile(githubOutput, output);
}

// Print summary
if (hasErrors) {
	console.log("‚ùå Size limit checks failed");
	process.exit(1);
} else {
	console.log("‚úÖ All size limit checks passed");
}
